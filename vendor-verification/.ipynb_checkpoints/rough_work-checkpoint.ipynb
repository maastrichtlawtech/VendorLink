{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b51332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import random\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from torch import cuda\n",
    "from tqdm import tqdm \n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "import spacy\n",
    "\n",
    "# from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from transformers import AutoModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "from transformers import BertTokenizer, BertTokenizerFast, BertForSequenceClassification\n",
    "\n",
    "\n",
    "# %% Loading custom libraries \n",
    "sys.path.append('../metrics/')\n",
    "# from performance import f1_score_func, accuracy_per_class\n",
    "\n",
    "# Loading the custom library\n",
    "sys.path.append('../process/')\n",
    "from load_data import FetchData, ContextualizedData\n",
    "from utils import merge_and_create_dataframe, train_model, evaluate_model, clean_and_merge_data_for_tokenization, add_tokens_to_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2599208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(ads_count=20,\n",
    " batch_size=64,\n",
    " cuda=False,\n",
    " data='alpha-dreams',\n",
    " data_dir='../data',\n",
    " delta=0.01,\n",
    " dropout=0.65,\n",
    " early_stopping=True,\n",
    " eval_per_steps=2000,\n",
    " hidden_states=512,\n",
    " load_model='bert_model.model',\n",
    " lr=4e-05,\n",
    " max_seq_len=512,\n",
    " mode='train',\n",
    " model='bert',\n",
    " n_splits=5,\n",
    " nb_epochs=10,\n",
    " patience=3,\n",
    " preprocess_flag=False,\n",
    " save_dir='/workspace/persistent/sybils-identification/train/../models/merged',\n",
    " seed=1111,\n",
    " setting='high',\n",
    " split_ratio=0.25,\n",
    " version='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Loading the datasets\n",
    "alpha_df = pd.read_csv(os.path.join(args['data_dir'], \"preprocessed_alpha.csv\"), error_bad_lines=False, \n",
    "                            lineterminator='\\n', usecols=['marketplace', 'title', 'vendor', 'prediction', 'ships_to', 'ships_from', 'description']).drop_duplicates()\n",
    "dreams_df = pd.read_csv(os.path.join(args['data_dir'], \"preprocessed_dreams.csv\"), error_bad_lines=False, \n",
    "                            lineterminator='\\n', usecols=['marketplace', 'title', 'vendor', 'prediction', 'ships_to', 'ships_from', 'description']).drop_duplicates()\n",
    "silk_df = pd.read_csv(os.path.join(args['data_dir'], \"preprocessed_silk.csv\"), error_bad_lines=False, \n",
    "                            lineterminator='\\n', usecols=['marketplace', 'title', 'vendor', 'prediction', 'ships_to', 'ships_from', 'description']).drop_duplicates()\n",
    "data_df = {\"alpha\":alpha_df, \"dreams\":dreams_df, \"silk\":silk_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7578a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(train_alpha_dreams, train_dreams_silk, train_alpha_silk, train_alpha_dreams_silk, train_alpha, train_dreams, train_silk), (test_alpha_dreams, test_dreams_silk, test_alpha_silk, test_alpha_dreams_silk, test_alpha, test_dreams, test_silk)] = FetchData(data_df, args[\"version\"], args[\"data\"],  args[\"split_ratio\"], args[\"preprocess_flag\"], args[\"setting\"], args[\"ads_count\"],  args[\"seed\"]).split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be5b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing class labels\n",
    "data = pd.concat([train_dreams, test_dreams])\n",
    "all_vendors = list(data['vendor'].unique())\n",
    "vendor_to_idx_dict = {vendor_name:index for index, vendor_name in enumerate(all_vendors)}\n",
    "train_dreams['vendor'] = train_dreams['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "test_dreams['vendor'] = test_dreams['vendor'].replace(vendor_to_idx_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9848f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data into the DataLoader format\n",
    "train_df = merge_and_create_dataframe(train_dreams)\n",
    "test_df = merge_and_create_dataframe(test_dreams)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.05, random_state=args[\"seed\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertTokenizerFast, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace <PATH-TO-SAVED-MODEL> with the real path of the saved model\n",
    "model_path = '../models/bert'\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', truncation=True, do_lower_case=True)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                            num_labels=len(vendor_to_idx_dict),\n",
    "                                            output_attentions=False,\n",
    "                                            output_hidden_states=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model.load_state_dict(torch.load(os.path.join(model_path, 'bert_model.model')))\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996886ae",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec836f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf2e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs):\n",
    "    return model(inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n",
    "\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c27299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_forward(inputs):\n",
    "    preds = predict(inputs)\n",
    "    return torch.softmax(preds, dim = 1)[0][1].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(custom_forward, model.bert.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc13764",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id)\n",
    "token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "indices = input_ids[0].detach().tolist()\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4120a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check predict output\n",
    "predict(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5234a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output of custom_forward\n",
    "custom_forward(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                    baselines=ref_input_ids,\n",
    "                                    n_steps=700,\n",
    "                                    internal_batch_size=3,\n",
    "                                    return_convergence_delta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = predict(input_ids)\n",
    "\n",
    "print('Advertisement: ', text)\n",
    "print('Prediction: ' + str(torch.argmax(score[0]).cpu().numpy()) + \\\n",
    "      ', Probability positive: ' + str(torch.softmax(score, dim = 1)[0][1].cpu().detach().numpy()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a28eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3b7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab671d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = score[0].cpu().detach().numpy()\n",
    "b = heapq.nlargest(10, range(len(a)), a.take)\n",
    "\n",
    "c = [list(vendor_to_idx_dict.keys())[list(vendor_to_idx_dict.values()).index(index)] for index in b]\n",
    "d = [a[index] for index in b]\n",
    "c[0] = \"mrcronk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure([go.Bar(x=c, y=d)])\n",
    "fig.update_layout(barmode='relative', \n",
    "                    title_text='',\n",
    "                    xaxis_title=\"Vendors\",\n",
    "                    yaxis_title=\"Probability\",\n",
    "                    xaxis = go.XAxis(showticklabels=True),\n",
    "                    yaxis = go.YAxis(showticklabels=True)\n",
    "                    )\n",
    "plotly.offline.plot(fig, filename =  \"vendor_prob.pdf\",auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355afa0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80bffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c5544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ef905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"attributions_sum = summarize_attributions(attributions)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# storing couple samples in an array for visualization purposes\n",
    "score_vis = viz.VisualizationDataRecord(attributions_sum,\n",
    "                                        torch.softmax(score, dim = 1)[0][1],\n",
    "                                        torch.argmax(torch.softmax(score, dim = 1)[0]),\n",
    "                                        test_df['labels'].iloc[0],\n",
    "                                        text,\n",
    "                                        attributions_sum.sum(),       \n",
    "                                        all_tokens,\n",
    "                                        delta)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print('\\033[1m', 'Visualization For Score', '\\033[0m')\n",
    "viz.visualize_text([score_vis])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer = SequenceClassificationExplainer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8a5598",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(vendor_to_idx_dict.keys())[list(vendor_to_idx_dict.values()).index(887)])\n",
    "samples = test_df[test_df['labels']==887]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864cd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['text'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a911058",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attributions = cls_explainer(samples['text'].iloc[1])\n",
    "semantics_dict = dict(word_attributions)\n",
    "advertisement = \" \".join(list(semantics_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ecfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cls_explainer.visualize(\"class_687_sample_4.pdf\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(advertisement)\n",
    "pos_tags = [token.pos_ for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208bd68",
   "metadata": {},
   "source": [
    "# symantics explaianations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(advertisement)\n",
    "pos_tags = [token.pos_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_column = list(semantics_dict.keys())\n",
    "atrributions_column = list(semantics_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d38c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(samples):\n",
    "    token_list, semantics_list, pos_list = ([] for i in range(3))\n",
    "    for i in range(samples.shape[0]):\n",
    "        word_attributions = cls_explainer(samples['text'].iloc[i])\n",
    "        semantics_dict = dict(word_attributions)\n",
    "        advertisement = \" \".join(list(semantics_dict.keys()))\n",
    "        \n",
    "        doc = nlp(advertisement)\n",
    "        pos_tags = [token.pos_ for token in doc]\n",
    "        \n",
    "        tokens_column = list(semantics_dict.keys())\n",
    "        atrributions_column = list(semantics_dict.values())\n",
    "        \n",
    "        token_list.append(tokens_column)\n",
    "        semantics_list.append(atrributions_column)\n",
    "        pos_list.append(pos_tags)\n",
    "        \n",
    "    return [item for sublist in token_list for item in sublist], [item for sublist in semantics_list for item in sublist], [item for sublist in pos_list for item in sublist] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107185d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = merge_data(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a), len(b), len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95523ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"tokens\":a, \"attribution\":b, \"pos\":c[:len(a)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_tokens = df[\"pos\"].unique()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_token_dict = {}\n",
    "for token in all_unique_tokens:\n",
    "    temp = df[df[\"pos\"]==token]\n",
    "    all_pos = temp['tokens'].unique()\n",
    "    final_pos_dict = {}\n",
    "    for pos in all_pos:\n",
    "        all_pos_temp = temp[temp[\"tokens\"] == pos]\n",
    "        final_pos_dict[pos] = all_pos_temp[\"attribution\"].mean()\n",
    "    final_token_dict[token] = final_pos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde60b0",
   "metadata": {},
   "source": [
    "# Evaluating trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60108f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_dreams, test_dreams, train_alpha, test_alpha, train_silk, test_silk])\n",
    "all_vendors = list(data['vendor'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ec96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vendor_to_idx_dict = {vendor_name:index for index, vendor_name in enumerate(all_vendors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_dreams['vendor'] = train_dreams['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "test_dreams['vendor'] = test_dreams['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "train_alpha['vendor'] = train_alpha['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "test_alpha['vendor'] = test_alpha['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "train_silk['vendor'] = train_silk['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "test_silk['vendor'] = test_silk['vendor'].replace(vendor_to_idx_dict, regex=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_alpha_silk['vendor'] = train_alpha_silk['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "train_alpha_dreams_silk['vendor'] = traian_alpha_dreams_silk['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "train_dreams_silk['vendor'] = train_dreams_silk['vendor'].replace(vendor_to_idx_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace <PATH-TO-SAVED-MODEL> with the real path of the saved model\n",
    "model_path = '../models/merged/bert'\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', truncation=True, do_lower_case=True)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                            num_labels=len(vendor_to_idx_dict),\n",
    "                                            output_attentions=False,\n",
    "                                            output_hidden_states=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model.load_state_dict(torch.load(os.path.join(\"../models/merged/bert/\", 'epoch_38.model')))\n",
    "model.eval()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_evaluation(test_data):\n",
    "    # vendors = [vendor if vendor in vendor_to_idx_dict.keys() else 'others' for vendor in test_data['vendor']]\n",
    "    # test_data['vendor'] = vendors\n",
    "    # test_data['vendor'] = test_data['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "    test_df = merge_and_create_dataframe(test_data)\n",
    "\n",
    "    encoded_data_test = tokenizer.batch_encode_plus(test_df.text.values, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True, \n",
    "                                            max_length=args['max_seq_len'], return_tensors='pt')\n",
    "    input_ids_test = encoded_data_test['input_ids']\n",
    "    attention_masks_test = encoded_data_test['attention_mask']\n",
    "    labels_test = torch.tensor(list(test_df.labels.values))\n",
    "\n",
    "    dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "    dataloader_test = DataLoader(dataset_test, sampler=SequentialSampler(dataset_test), batch_size=args[\"batch_size\"])\n",
    "\n",
    "    return dataloader_test\n",
    "\n",
    "# Evaluating on the Dreams dataset\n",
    "dataloader_test = create_data_for_evaluation(test_dreams)\n",
    "_, predictions, true_vals = evaluate_model(model, dataloader_test, device)\n",
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "print(f'F1 Score for Dreams dataset (Weighted): {val_f1}')\n",
    "\n",
    "# Evaluating on the Alphabay dataset\n",
    "dataloader_test = create_data_for_evaluation(test_alpha)\n",
    "_, predictions, true_vals = evaluate_model(model, dataloader_test, device)\n",
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "print(f'F1 Score for Alphabay dataset (Weighted): {val_f1}')\n",
    "\n",
    "# Evaluation on the Silk-Road dataset\n",
    "dataloader_test = create_data_for_evaluation(test_silk)\n",
    "_, predictions, true_vals = evaluate_model(model, dataloader_test, device)\n",
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "print(f'F1 Score for Silk-Road dataset (Weighted): {val_f1}')\n",
    "\n",
    "# Evaluation on the Alphabay-Silk Road dataset\n",
    "dataloader_test = create_data_for_evaluation(test_alpha_silk)\n",
    "_, predictions, true_vals = evaluate_model(model, dataloader_test, device)\n",
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "print(f'F1 Score for Alphabay-Silk-Road dataset (Weighted): {val_f1}')\n",
    "\n",
    "# Evaluation on the Alphabay-Dreams dataset\n",
    "dataloader_test = create_data_for_evaluation(test_alpha_dreams)\n",
    "_, predictions, true_vals = evaluate_model(model, dataloader_test, device)\n",
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "print(f'F1 Score for Alphabay-Dream dataset (Weighted): {val_f1}')\n",
    "\n",
    "# Evaluation on the Dreams-Silk-Road dataset\n",
    "dataloader_test = create_data_for_evaluation(test_dreams_silk)\n",
    "_, predictions, true_vals = evaluate_model(model, dataloader_test, device)\n",
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "print(f'F1 Score for Dreams-Silk-Road dataset (Weighted): {val_f1}')\n",
    "\n",
    "# Evaluation on the Alphabay-Dreams-Silk-Road dataset\n",
    "dataloader_test = create_data_for_evaluation(test_alpha_dreams_silk)\n",
    "_, predictions, true_vals = evaluate_model(model, dataloader_test, device)\n",
    "val_f1 = f1_score_func(predictions, true_vals)\n",
    "print(f'F1 Score for Alphabay-Dreams-Silk-Road dataset (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11d5c3",
   "metadata": {},
   "source": [
    "# Finding accuracy per class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e461c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels, label_dict):\n",
    "    acc_per_class = {}\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        # print(f'Class: {label_dict_inverse[label]}')\n",
    "        # print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "        acc_per_class[label_dict_inverse[label]] = float(len(y_preds[y_preds==label])/len(y_true))\n",
    "    \n",
    "    return acc_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_evaluation(test_data):\n",
    "    vendors = [vendor if vendor in vendor_to_idx_dict.keys() else 'others' for vendor in test_data['vendor']]\n",
    "    test_data['vendor'] = vendors\n",
    "    test_data['vendor'] = test_data['vendor'].replace(vendor_to_idx_dict, regex=True)\n",
    "    test_df = merge_and_create_dataframe(test_data)\n",
    "    \n",
    "    encoded_data_test = tokenizer.batch_encode_plus(test_df.text.values, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True, \n",
    "                                            max_length=args['max_seq_len'], return_tensors='pt')\n",
    "    input_ids_test = encoded_data_test['input_ids']\n",
    "    attention_masks_test = encoded_data_test['attention_mask']\n",
    "    \n",
    "    labels_test = torch.tensor(list(test_df.labels.values))\n",
    "\n",
    "    dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "    dataloader_test = DataLoader(dataset_test, sampler=SequentialSampler(dataset_test), batch_size=args[\"batch_size\"])\n",
    "\n",
    "    return dataloader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d14dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on the Dreams dataset\n",
    "dataloader_test = create_data_for_evaluation(test_dreams)\n",
    "_, predictions, true_vals = evaluate_model(model, dataloader_test, device)\n",
    "acc = accuracy_per_class(predictions, true_vals, vendor_to_idx_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d032bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/acc_per_class/bert/test_dreams.pickle', 'wb') as handle:\n",
    "    pickle.dump(acc, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227050c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa7ace4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118b6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c064d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
